{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flowers-objax.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "094Kz02rM5WC",
        "outputId": "b1c238f0-7bb5-4a40-ea0b-b2710f5c0524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "! pip install objax"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting objax\n",
            "  Downloading https://files.pythonhosted.org/packages/88/bd/b105855a6093bb0c05d42723ce5680d6149ed36f407f8f444917cf3e458b/objax-1.0.2.tar.gz\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from objax) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.6/dist-packages (from objax) (1.18.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from objax) (7.0.0)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.6/dist-packages (from objax) (0.1.52)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.6/dist-packages (from objax) (0.1.75)\n",
            "Requirement already satisfied: tensorboard>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from objax) (2.3.0)\n",
            "Collecting parameterized\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/6b/73dfed0ab5299070cf98451af50130989901f50de41fe85d605437a0210f/parameterized-0.7.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from jaxlib->objax) (0.10.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.6/dist-packages (from jax->objax) (3.3.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.3.0->objax) (2.23.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.3.0->objax) (0.35.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.3.0->objax) (50.3.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.3.0->objax) (1.17.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.3.0->objax) (3.12.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.3.0->objax) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.3.0->objax) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.3.0->objax) (3.2.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.3.0->objax) (1.32.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.3.0->objax) (1.7.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.3.0->objax) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3.0->objax) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3.0->objax) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3.0->objax) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.3.0->objax) (2020.6.20)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.3.0->objax) (4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.3.0->objax) (4.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.3.0->objax) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3.0->objax) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.3.0->objax) (1.7.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=2.3.0->objax) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.3.0->objax) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.3.0->objax) (3.1.0)\n",
            "Building wheels for collected packages: objax\n",
            "  Building wheel for objax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for objax: filename=objax-1.0.2-cp36-none-any.whl size=57983 sha256=ae7e201dae509b80a46594aa17967ac16ebd5fa7303ea33c077bd89bdd1b1bfc\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/73/a8/df38d6aa0448d888b2111d2493e6aaf6b6320289250c83e891\n",
            "Successfully built objax\n",
            "Installing collected packages: parameterized, objax\n",
            "Successfully installed objax-1.0.2 parameterized-0.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIZtu9iFM9HH"
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import tensorflow\n",
        "import objax\n",
        "from objax.zoo.resnet_v2 import ResNet50\n",
        "import jax\n",
        "import jax.numpy as jn\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Jauh5eF_ga",
        "outputId": "efa3d381-4d5c-4c9c-ac9b-4a1cdea8c5a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "! ls ./drive/My\\ Drive/mlin/flower-imgs"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test  train  val\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIVZ5a98NF6R"
      },
      "source": [
        "fnames = list(map(lambda fn: f'./drive/My Drive/mlin/flower-imgs/train/{fn}', os.listdir('./drive/My Drive/mlin/flower-imgs/train')))\n",
        "test_names = list(map(lambda fn: f'./drive/My Drive/mlin/flower-imgs/val/{fn}', os.listdir('./drive/My Drive/mlin/flower-imgs/val')))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf3_qHXGQQoO",
        "outputId": "7367f7e9-0339-4415-953f-5a77aa0a9bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from absl import app, flags, logging\n",
        "\n",
        "flags.DEFINE_string('model_dir', '', 'Model directory.')\n",
        "flags.DEFINE_integer('train_device_batch_size', 64, 'Per-device training batch size.')\n",
        "flags.DEFINE_integer('eval_device_batch_size', 250, 'Per-device eval batch size.')\n",
        "flags.DEFINE_integer('max_eval_batches', -1, 'Maximum number of batches used for evaluation, '\n",
        "                                             'zero or negative number means use all batches.')\n",
        "flags.DEFINE_integer('eval_every_n_steps', 1000, 'How often to run eval.')\n",
        "flags.DEFINE_float('num_train_epochs', 90, 'Number of training epochs.')\n",
        "flags.DEFINE_float('base_learning_rate', 0.1, 'Base learning rate.')\n",
        "flags.DEFINE_float('weight_decay', 1e-4, 'Weight decay (L2 loss) coefficient.')\n",
        "flags.DEFINE_boolean('use_sync_bn', True, 'If true then use synchronized batch normalization, '\n",
        "                                          'otherwise use per-replica batch normalization.')\n",
        "flags.DEFINE_string('tfds_data_dir', None, 'Optional TFDS data directory.')\n",
        "\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "# running internally, not from cli\n",
        "FLAGS = flags.FLAGS\n",
        "FLAGS(['a', 'b', 'c'])\n",
        "FLAGS.train_device_batch_size"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv-wXbaSNHTf"
      },
      "source": [
        "IMAGE_SIZE = [192, 192] \n",
        "BATCH_SIZE = FLAGS.train_device_batch_size #32 * 2 #strategy.num_replicas_in_sync\n",
        "AUTO = tensorflow.data.experimental.AUTOTUNE\n",
        "\n",
        "def decode_image(image_data):\n",
        "    image = tensorflow.image.decode_jpeg(image_data, channels=3)\n",
        "    image = tensorflow.cast(image, tensorflow.float32) / 255.0  \n",
        "    image = tensorflow.reshape(image, [*IMAGE_SIZE, 3]) \n",
        "    return image\n",
        "\n",
        "\n",
        "def read_labeled_tfrecord(example):\n",
        "    LABELED_TFREC_FORMAT = {\n",
        "        \"image\": tensorflow.io.FixedLenFeature([], tensorflow.string), \n",
        "        \"class\": tensorflow.io.FixedLenFeature([], tensorflow.int64),  \n",
        "    }\n",
        "    example = tensorflow.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    label = tensorflow.cast(example['class'], tensorflow.int32)\n",
        "    return image, label \n",
        "\n",
        "\n",
        "def read_unlabeled_tfrecord(example):\n",
        "    UNLABELED_TFREC_FORMAT = {\n",
        "        \"image\": tensorflow.io.FixedLenFeature([], tensorflow.string), \n",
        "        \"id\": tensorflow.io.FixedLenFeature([], tensorflow.string), \n",
        "    }\n",
        "    example = tensorflow.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
        "    image = decode_image(example['image'])\n",
        "    idnum = example['id']\n",
        "    return image, idnum \n",
        "\n",
        "\n",
        "def load_dataset(filenames, labeled = True, ordered = False):\n",
        "    \n",
        "    ignore_order = tensorflow.data.Options()\n",
        "    if not ordered:\n",
        "        ignore_order.experimental_deterministic = False \n",
        "        \n",
        "    dataset = tensorflow.data.TFRecordDataset(filenames, num_parallel_reads = AUTO) \n",
        "    dataset = dataset.with_options(ignore_order) \n",
        "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls = AUTO) \n",
        "    return dataset\n",
        "\n",
        "\n",
        "def data_augment(image, label):\n",
        "\n",
        "    image = tensorflow.image.random_flip_left_right(image)\n",
        "    return image, label   \n",
        "\n",
        "def get_training_dataset(dataset,do_aug=True):\n",
        "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
        "    if do_aug: dataset = dataset.map(transform, num_parallel_calls=AUTO)\n",
        "    dataset = dataset.repeat() \n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    #dataset = dataset.prefetch(AUTO) \n",
        "    return dataset\n",
        "\n",
        "def get_validation_dataset(dataset):\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.cache()\n",
        "    dataset = dataset.prefetch(AUTO) \n",
        "    return dataset\n",
        "\n",
        "def get_test_dataset(ordered=False):\n",
        "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "    dataset = dataset.prefetch(AUTO) \n",
        "    return dataset"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuKT1QdLNPrZ"
      },
      "source": [
        "all_elements = get_training_dataset(load_dataset(fnames),do_aug=False)\n",
        "itrrr = all_elements.as_numpy_iterator()\n",
        "\n",
        "test_elements = get_training_dataset(load_dataset(test_names),do_aug=False).take(64 * 6)\n",
        "test_iter = test_elements.as_numpy_iterator()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOZivwVBRDx6",
        "outputId": "3c737945-006e-4673-d8be-5b669be7d4c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#batch = next(itrrr)\n",
        "#tensorflow.transpose(batch[0], [0, 3, 1, 2]).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 3, 192, 192])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTkydO00NTqB"
      },
      "source": [
        "NUM_CLASSES = 104\n",
        "\n",
        "class Experiment:\n",
        "    # based on https://github.com/google/objax/blob/master/examples/classify/img/imagenet/imagenet_train.py\n",
        "\n",
        "    def __init__(self):\n",
        "        # Some constants\n",
        "        total_batch_size = FLAGS.train_device_batch_size * jax.device_count()\n",
        "        self.eval_batch_index = -1\n",
        "        self.base_learning_rate = FLAGS.base_learning_rate * total_batch_size / 256\n",
        "        # Create model\n",
        "        bn_cls = objax.nn.SyncedBatchNorm2D if FLAGS.use_sync_bn else objax.nn.BatchNorm2D\n",
        "        self.model = ResNet50(in_channels=3, num_classes=NUM_CLASSES, normalization_fn=bn_cls)\n",
        "        self.model_vars = self.model.vars()\n",
        "        #print(self.model_vars)\n",
        "        # Create parallel eval op\n",
        "        self.evaluate_batch_parallel = objax.Parallel(self.evaluate_batch, self.model_vars,\n",
        "                                                      reduce=lambda x: x.sum(0))\n",
        "        # Create parallel training op\n",
        "        self.optimizer = objax.optimizer.Momentum(self.model_vars, momentum=0.9, nesterov=True)\n",
        "        self.compute_grads_loss = objax.GradValues(self.loss_fn, self.model_vars)\n",
        "        self.all_vars = self.model_vars + self.optimizer.vars()\n",
        "        self.train_op_parallel = objax.Parallel(\n",
        "            self.train_op, self.all_vars, reduce=lambda x: x[0])\n",
        "        # Summary writer\n",
        "        self.summary_writer = objax.jaxboard.SummaryWriter(os.path.join(\n",
        "            FLAGS.model_dir, 'tb'))\n",
        "\n",
        "    def evaluate_batch(self, images, labels):\n",
        "        logits = self.model(images, training=False)\n",
        "        num_correct = jn.count_nonzero(jn.equal(jn.argmax(logits, axis=1), labels))\n",
        "        return num_correct\n",
        "\n",
        "    def run_eval(self):\n",
        "        print(\"eval:\")\n",
        "        \"\"\"Runs evaluation and returns top-1 accuracy.\"\"\"\n",
        "        correct_pred = 0\n",
        "        total_examples = 0\n",
        "        test_iter = test_elements.as_numpy_iterator()\n",
        "        for batch in test_iter:\n",
        "            self.eval_batch_index += 1\n",
        "            imgs = jn.array(tensorflow.transpose(batch[0], [0, 3, 1, 2]))\n",
        "\n",
        "            correct_pred += self.evaluate_batch_parallel(imgs,\n",
        "                                                         batch[1])\n",
        "            total_examples += imgs.shape[0]\n",
        "            if ((FLAGS.max_eval_batches > 0)\n",
        "                    and (self.eval_batch_index + 1 >= FLAGS.max_eval_batches)):\n",
        "                break\n",
        "\n",
        "        return correct_pred / total_examples\n",
        "\n",
        "    def loss_fn(self, images, labels):\n",
        "        \"\"\"Computes loss function.\n",
        "        Args:\n",
        "          images: tensor with images NCHW\n",
        "          labels: tensors with dense labels, shape (batch_size,)\n",
        "        Returns:\n",
        "          Tuple (total_loss, losses_dictionary).\n",
        "        \"\"\"\n",
        "        #print(images.shape)\n",
        "        logits = self.model(images, training=True)\n",
        "        xent_loss = objax.functional.loss.cross_entropy_logits_sparse(logits, labels).mean()\n",
        "        wd_loss = FLAGS.weight_decay * 0.5 * sum((v.value ** 2).sum()\n",
        "                                                 for k, v in self.model_vars.items()\n",
        "                                                 if k.endswith('.w'))\n",
        "        total_loss = xent_loss + wd_loss\n",
        "        return total_loss, {'total_loss': total_loss,\n",
        "                            'xent_loss': xent_loss,\n",
        "                            'wd_loss': wd_loss}\n",
        "\n",
        "    def learning_rate(self, epoch: float):\n",
        "        \"\"\"Computes learning rate for given fractional epoch.\"\"\"\n",
        "        # Linear warm up to base_learning_rate value for first 5 epochs.\n",
        "        # Then use 1.0 * base_learning_rate until epoch 30\n",
        "        # Then use 0.1 * base_learning_rate until epoch 60\n",
        "        # Then use 0.01 * base_learning_rate until epoch 80\n",
        "        # Then use 0.001 * base_learning_rate until until end of traning.\n",
        "        lr_linear_till = 5\n",
        "        boundaries = jn.array((30, 60, 80))\n",
        "        values = jn.array([1., 0.1, 0.01, 0.001]) * self.base_learning_rate\n",
        "\n",
        "        index = jn.sum(boundaries < epoch)\n",
        "        lr = jn.take(values, index)\n",
        "        return lr * jn.minimum(1., epoch / lr_linear_till)\n",
        "\n",
        "    def train_op(self, images, labels, cur_epoch):\n",
        "        cur_epoch = cur_epoch[0]  # because cur_epoch is array of size 1\n",
        "        grads, (_, losses_dict) = self.compute_grads_loss(images, labels)\n",
        "        grads = objax.functional.parallel.pmean(grads)\n",
        "        losses_dict = objax.functional.parallel.pmean(losses_dict)\n",
        "        learning_rate = self.learning_rate(cur_epoch)\n",
        "        self.optimizer(learning_rate, grads)\n",
        "        return dict(**losses_dict, learning_rate=learning_rate, epoch=cur_epoch)\n",
        "\n",
        "    def train_and_eval(self):\n",
        "        \"\"\"Runs training and evaluation.\"\"\"\n",
        "\n",
        "        steps_per_epoch = 100 #num_exampls / (FLAGS.train_device_batch_size * jax.device_count())\n",
        "        total_train_steps = int(steps_per_epoch * FLAGS.num_train_epochs)\n",
        "        eval_every_n_steps = FLAGS.eval_every_n_steps\n",
        "\n",
        "        checkpoint = objax.io.Checkpoint(FLAGS.model_dir, keep_ckpts=10)\n",
        "        start_step, _ = checkpoint.restore(self.all_vars)\n",
        "        cur_epoch = np.zeros([jax.local_device_count()], dtype=np.float32)\n",
        "        for big_step in range(start_step, total_train_steps, eval_every_n_steps):\n",
        "            print(f'Running training steps {big_step + 1} - {big_step + eval_every_n_steps}')\n",
        "            with self.all_vars.replicate():\n",
        "                # training\n",
        "                start_time = time.time()\n",
        "                for cur_step in range(big_step + 1, big_step + eval_every_n_steps + 1):\n",
        "                    batch = next(itrrr)\n",
        "                    cur_epoch[:] = cur_step / steps_per_epoch\n",
        "                    imgs = jn.array(tensorflow.transpose(batch[0], [0, 3, 1, 2])) #.numpy()\n",
        "                    # print(imgs.shape)\n",
        "                    monitors = self.train_op_parallel(imgs, batch[1], cur_epoch)\n",
        "                elapsed_train_time = time.time() - start_time\n",
        "                # eval\n",
        "                start_time = time.time()\n",
        "                accuracy = self.run_eval()\n",
        "                elapsed_eval_time = time.time() - start_time\n",
        "            # save summary\n",
        "            summary = objax.jaxboard.Summary()\n",
        "            for k, v in monitors.items():\n",
        "                summary.scalar(f'train/{k}', v)\n",
        "            # # Uncomment following two lines to save summary with training images\n",
        "            # summary.image('input/train_img',\n",
        "            #               imagenet_data.normalize_image_for_view(batch['images'][0]))\n",
        "            summary.scalar('test/accuracy', accuracy * 100)\n",
        "            self.summary_writer.write(summary, step=cur_step)\n",
        "            # save checkpoint\n",
        "            checkpoint.save(self.all_vars, cur_step)\n",
        "            # print info\n",
        "            print('Step %d -- Epoch %.2f -- Loss %.2f  Accuracy %.2f'\n",
        "                  % (cur_step, cur_step / steps_per_epoch,\n",
        "                     monitors['total_loss'], accuracy * 100))\n",
        "            print('    Training took %.1f seconds, eval took %.1f seconds'\n",
        "                  % (elapsed_train_time, elapsed_eval_time), flush=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhjqXbTRh8es",
        "outputId": "6bc82c7b-45c2-4911-debb-4dffc88077b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### Optional cell - activate TPU backend\n",
        "import requests\n",
        "import os\n",
        "if 'TPU_DRIVER_MODE' not in globals():\n",
        "  url = 'http://' + os.environ['COLAB_TPU_ADDR'].split(':')[0] + ':8475/requestversion/tpu_driver0.1-dev20191206'\n",
        "  resp = requests.post(url)\n",
        "  TPU_DRIVER_MODE = 1\n",
        "\n",
        "# The following is required to use TPU Driver as JAX's backend.\n",
        "from jax.config import config\n",
        "config.FLAGS.jax_xla_backend = \"tpu_driver\"\n",
        "config.FLAGS.jax_backend_target = \"grpc://\" + os.environ['COLAB_TPU_ADDR']\n",
        "print(config.FLAGS.jax_backend_target)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "grpc://10.7.42.194:8470\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3_-8Bx5NkCp",
        "outputId": "701b6e11-4d5c-4851-a368-e336d407c91a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "experiment = Experiment()\n",
        "experiment.train_and_eval()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running training steps 1 - 1000\n",
            "eval:\n",
            "Step 1000 -- Epoch 10.00 -- Loss 4.05  Accuracy 1.01\n",
            "    Training took 590.5 seconds, eval took 193.4 seconds\n",
            "Running training steps 1001 - 2000\n",
            "eval:\n",
            "Step 2000 -- Epoch 20.00 -- Loss 2.86  Accuracy 7.84\n",
            "    Training took 577.7 seconds, eval took 186.2 seconds\n",
            "Running training steps 2001 - 3000\n",
            "eval:\n",
            "Step 3000 -- Epoch 30.00 -- Loss 2.10  Accuracy 34.55\n",
            "    Training took 582.6 seconds, eval took 185.4 seconds\n",
            "Running training steps 3001 - 4000\n",
            "eval:\n",
            "Step 4000 -- Epoch 40.00 -- Loss 1.30  Accuracy 61.31\n",
            "    Training took 583.7 seconds, eval took 187.2 seconds\n",
            "Running training steps 4001 - 5000\n",
            "eval:\n",
            "Step 5000 -- Epoch 50.00 -- Loss 1.22  Accuracy 60.05\n",
            "    Training took 585.2 seconds, eval took 185.6 seconds\n",
            "Running training steps 5001 - 6000\n",
            "eval:\n",
            "Step 6000 -- Epoch 60.00 -- Loss 1.19  Accuracy 61.80\n",
            "    Training took 583.4 seconds, eval took 185.3 seconds\n",
            "Running training steps 6001 - 7000\n",
            "eval:\n",
            "Step 7000 -- Epoch 70.00 -- Loss 1.15  Accuracy 69.16\n",
            "    Training took 588.4 seconds, eval took 186.2 seconds\n",
            "Running training steps 7001 - 8000\n",
            "eval:\n",
            "Step 8000 -- Epoch 80.00 -- Loss 1.14  Accuracy 70.18\n",
            "    Training took 587.7 seconds, eval took 185.6 seconds\n",
            "Running training steps 8001 - 9000\n",
            "eval:\n",
            "Step 9000 -- Epoch 90.00 -- Loss 1.14  Accuracy 70.42\n",
            "    Training took 584.6 seconds, eval took 184.2 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}